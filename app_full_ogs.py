
import numpy as np
import sounddevice as sd
import whisper
from collections import deque
import keyboard
import torch

# ==== Settings / –ù–∞—Å—Ç—Ä–æ–π–∫–∏ ====
SAMPLE_RATE = 16000  # Do not change, sound quality to send to AI / –ù–µ –∏–∑–º–µ–Ω—è–π, –∫–∞—á–µ—Å—Ç–≤–æ –∑–≤—É–∫–∞ –¥–ª—è –ø–µ—Ä–µ–¥–∞—á–∏ –≤ –ò–ò
CHUNK_DURATION = 0.3  # Do not change, Chunk duration in seconds / –î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Ñ—Ä–∞–≥–º–µ–Ω—Ç–∞ –≤ —Å–µ–∫—É–Ω–¥–∞—Ö
WHISPER_MODEL = 'small'  # tiny / base / small / medium / large  Whisper model being used / –ò—Å–ø–æ–ª—å–∑—É–µ–º–∞—è –º–æ–¥–µ–ª—å Whisper   
#C:\Users\_USER_\.cache\whisper  Model will be loaded  here 
THRESHOLD = 0.015  # Sound sensitivity / –ß—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∫ –∑–≤—É–∫—É

SILENCE_DURATION = 0.3  # Silence duration before stopping / –î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Ç–∏—à–∏–Ω—ã –ø–µ—Ä–µ–¥ –æ—Å—Ç–∞–Ω–æ–≤–∫–æ–π
PRE_RECORD_SECONDS = 1.0  # Length of the "past" sound buffer / –î–ª–∏–Ω–∞ –±—É—Ñ–µ—Ä–∞ "–ø—Ä–æ—à–ª–æ–≥–æ" –∑–≤—É–∫–∞
LANGUAGE = 'en'  # Processing language / –Ø–∑—ã–∫ –æ–±—Ä–∞–±–æ—Ç–∫–∏



# üîí Hotkeys / –ì–æ—Ä—è—á–∏–µ —Ñ—Ä–∞–∑—ã
hotkey0 = ""  
hotkey1 = "healing"
hotkey2 = ""
hotkey3 = "fireball"
hotkey4 = ""
hotkey5 = ""
hotkey6 = ""
hotkey7 = ""
hotkey8 = ""
hotkey9 = ""
stop_word = "—Å—Ç–æ–ø"  
stop_word2 = "stop"

# === Device identification / –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞ ===

if torch.cuda.is_available():
    DEVICE = "cuda"
    FP16 = True
    print("‚ö° Using GPU (CUDA) /  –ò—Å–ø–æ–ª—å–∑—É–µ–º GPU (CUDA)")
else:
    DEVICE = "cpu"
    FP16 = False
    print("üñ• Using CPU / –ò—Å–ø–æ–ª—å–∑—É–µ–º CPU")

print("CUDA  avalible / –¥–æ—Å—Ç—É–ø–Ω–∞:", torch.cuda.is_available())
if torch.cuda.is_available():
    print("Device qty / –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —É—Å—Ç—Ä–æ–π—Å—Ç–≤:", torch.cuda.device_count())
    print("Device name / –ò–º—è —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞:", torch.cuda.get_device_name(0))


# === Model Loading === ‚Üí # === –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ ===

print("üß† / Loading Whisper model / –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å Whisper...")
model = whisper.load_model(f"{WHISPER_MODEL}", device=DEVICE)

# === Sending Keystrokes === ‚Üí # === –û—Ç–ø—Ä–∞–≤–∫–∞ –∫–ª–∞–≤–∏—à ===
def send_hotkey(key):
    if 0 <= key <= 9:
        try:
            keyboard.send(str(key))  # –æ–±—ã—á–Ω–∞—è —Ü–∏—Ñ—Ä–∞
        except ValueError as e:
            print(f"‚ùå Error while sending / –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ç–ø—Ä–∞–≤–∫–µ: {e}")
    else:
        print("‚ùå Error: key out of range 0‚Äì9  / –û—à–∏–±–∫–∞: –∫–ª—é—á –≤–Ω–µ –¥–∏–∞–ø–∞–∑–æ–Ω–∞ 0‚Äì9")

# === Command Processing === ‚Üí # === –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–æ–º–∞–Ω–¥—ã ===
def handle_command(text):
    text = text.strip().lower()
    if stop_word in text or stop_word2 in text:
        print("üö© Command 'stop' received ‚Äî terminating. / –ü–æ–ª—É—á–µ–Ω–∞ –∫–æ–º–∞–Ω–¥–∞ '—Å—Ç–æ–ø' ‚Äî –∑–∞–≤–µ—Ä—à–µ–Ω–∏–µ.")
        return False

    for i in range(10):
        hotkey = globals().get(f"hotkey{i}")
        if hotkey and hotkey in text:
            print(f"üéØ Hotkey triggered / –°—Ä–∞–±–æ—Ç–∞–ª hotkey{i} ('{hotkey}') ‚Äî sending / –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º {i}")
            send_hotkey(i)
            return True

    print("ü§∑ Command not recognized / –ö–æ–º–∞–Ω–¥–∞ –Ω–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–∞")
    return True

# === –ü—Ä–æ–≤–µ—Ä–∫–∞ –≥—Ä–æ–º–∫–æ—Å—Ç–∏ ===
def is_loud(data, threshold):
    return np.max(np.abs(data)) > threshold

# === –û—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª –ø—Ä–æ—Å–ª—É—à–∏–≤–∞–Ω–∏—è ===
def listen_loop():
    print("üéß Starting infinite listening loop...  / –ù–∞—á–∏–Ω–∞–µ–º –±–µ—Å–∫–æ–Ω–µ—á–Ω—ã–π —Ü–∏–∫–ª –ø—Ä–æ—Å–ª—É—à–∏–≤–∞–Ω–∏—è...")

    buffer_chunks = int(PRE_RECORD_SECONDS / CHUNK_DURATION)
    pre_buffer = deque(maxlen=buffer_chunks)

    device_info = sd.query_devices(kind='input')
    input_channels = device_info['max_input_channels']
    print(f"üéöÔ∏è Detected input channels / –û–±–Ω–∞—Ä—É–∂–µ–Ω–æ –≤—Ö–æ–¥–Ω—ã—Ö –∫–∞–Ω–∞–ª–æ–≤: {input_channels}")

    while True:
        print("üîé Waiting for sound... / –û–∂–∏–¥–∞–Ω–∏–µ –∑–≤—É–∫–∞...")

        recording = []
        silence_time = 0.0
        recording_started = False
        stop_stream = False

        def callback(indata, frames, time_info, status):
            nonlocal recording, silence_time, recording_started, stop_stream

            volume = np.linalg.norm(indata)
            print(f"üîä MIC Volume / –ì—Ä–æ–º–∫–æ—Å—Ç—å: {volume:.5f}")

            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ –º–æ–Ω–æ, –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
            if indata.shape[1] > 1:
                mono_data = np.mean(indata, axis=1, keepdims=True)
            else:
                mono_data = indata

            pre_buffer.append(mono_data.copy())

            if is_loud(mono_data, THRESHOLD):
                if not recording_started:
                    print("üî¥ Sound detected, starting recording... / –û–±–Ω–∞—Ä—É–∂–µ–Ω –∑–≤—É–∫, –Ω–∞—á–∏–Ω–∞–µ–º –∑–∞–ø–∏—Å—å...")
                    recording.extend(list(pre_buffer))
                    recording_started = True
                silence_time = 0.0
                recording.append(mono_data.copy())
            elif recording_started:
                silence_time += CHUNK_DURATION
                print(f"üü° Silence / –¢–∏—à–∏–Ω–∞ {silence_time:.2f} —Å–µ–∫...")
                recording.append(mono_data.copy())
                if silence_time >= SILENCE_DURATION:
                    print("‚èπÔ∏è Recording finished / –ó–∞–ø–∏—Å—å –∑–∞–≤–µ—Ä—à–µ–Ω–∞")
                    stop_stream = True

        with sd.InputStream(callback=callback,
                            channels=input_channels,
                            samplerate=SAMPLE_RATE,
                            blocksize=int(SAMPLE_RATE * CHUNK_DURATION)):
            while not stop_stream:
                sd.sleep(int(CHUNK_DURATION * 1000))

        if not recording:
            print("üü° Sound not detected ‚Äî nothing recognized / –ó–≤—É–∫ –Ω–µ –±—ã–ª –æ–±–Ω–∞—Ä—É–∂–µ–Ω ‚Äî –Ω–∏—á–µ–≥–æ –Ω–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–æ")
            continue

        print(f"‚úÖ Processing / –û–±—Ä–∞–±–æ—Ç–∫–∞ {len(recording)} cunks / —á–∞–Ω–∫–æ–≤...")
        full = np.concatenate(recording).flatten().astype(np.float32)

        try:
            result = model.transcribe(full, language=LANGUAGE, fp16=FP16)
            print("üìù Recognized text / –†–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç:", result["text"])
            if not handle_command(result["text"]):
                break
        except Exception as e:
            print(f"‚ùå Error during recognition / –û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–∏: {e}")

# === –¢–æ—á–∫–∞ –≤—Ö–æ–¥–∞ ===
if __name__ == "__main__":
    listen_loop()
